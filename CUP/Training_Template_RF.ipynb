{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFR (Random Forest Regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn.preprocessing import minmax_scale\n",
    "%matplotlib inline\n",
    "from scipy import stats\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from pandas import read_csv\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "import itertools \n",
    "from time import time\n",
    "from functools import reduce \n",
    "import operator\n",
    "\n",
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))\n",
    "\n",
    "#Seaborn\n",
    "import seaborn as sns #Visualization\n",
    "plt.rcParams['figure.figsize'] = [8,5]\n",
    "plt.rcParams['font.size'] =14\n",
    "plt.rcParams['font.weight']= 'bold'\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor # Import model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                X1           X2           X3           X4           X5  \\\n",
       "count  1524.000000  1524.000000  1524.000000  1524.000000  1524.000000   \n",
       "mean      0.493986     0.455558     0.422902     0.532771     0.542641   \n",
       "std       0.229482     0.218699     0.211772     0.174884     0.209266   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.277706     0.261214     0.236137     0.407235     0.353918   \n",
       "50%       0.515967     0.464428     0.416107     0.527146     0.576631   \n",
       "75%       0.686938     0.638466     0.584685     0.648318     0.715638   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "                X6           X7           X8           X9          X10  \\\n",
       "count  1524.000000  1524.000000  1524.000000  1524.000000  1524.000000   \n",
       "mean      0.556990     0.448495     0.479733     0.477938     0.494039   \n",
       "std       0.168283     0.216930     0.206977     0.214500     0.224177   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.448039     0.244393     0.305093     0.281794     0.286610   \n",
       "50%       0.533931     0.475399     0.480954     0.482409     0.536919   \n",
       "75%       0.665114     0.635441     0.637042     0.659932     0.668569   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "                Y1           Y2  \n",
       "count  1524.000000  1524.000000  \n",
       "mean      0.425603     0.351685  \n",
       "std       0.287916     0.271691  \n",
       "min       0.000000     0.000000  \n",
       "25%       0.164375     0.130400  \n",
       "50%       0.366169     0.296888  \n",
       "75%       0.672862     0.502768  \n",
       "max       1.000000     1.000000  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X1</th>\n      <th>X2</th>\n      <th>X3</th>\n      <th>X4</th>\n      <th>X5</th>\n      <th>X6</th>\n      <th>X7</th>\n      <th>X8</th>\n      <th>X9</th>\n      <th>X10</th>\n      <th>Y1</th>\n      <th>Y2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1524.000000</td>\n      <td>1524.000000</td>\n      <td>1524.000000</td>\n      <td>1524.000000</td>\n      <td>1524.000000</td>\n      <td>1524.000000</td>\n      <td>1524.000000</td>\n      <td>1524.000000</td>\n      <td>1524.000000</td>\n      <td>1524.000000</td>\n      <td>1524.000000</td>\n      <td>1524.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.493986</td>\n      <td>0.455558</td>\n      <td>0.422902</td>\n      <td>0.532771</td>\n      <td>0.542641</td>\n      <td>0.556990</td>\n      <td>0.448495</td>\n      <td>0.479733</td>\n      <td>0.477938</td>\n      <td>0.494039</td>\n      <td>0.425603</td>\n      <td>0.351685</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.229482</td>\n      <td>0.218699</td>\n      <td>0.211772</td>\n      <td>0.174884</td>\n      <td>0.209266</td>\n      <td>0.168283</td>\n      <td>0.216930</td>\n      <td>0.206977</td>\n      <td>0.214500</td>\n      <td>0.224177</td>\n      <td>0.287916</td>\n      <td>0.271691</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.277706</td>\n      <td>0.261214</td>\n      <td>0.236137</td>\n      <td>0.407235</td>\n      <td>0.353918</td>\n      <td>0.448039</td>\n      <td>0.244393</td>\n      <td>0.305093</td>\n      <td>0.281794</td>\n      <td>0.286610</td>\n      <td>0.164375</td>\n      <td>0.130400</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.515967</td>\n      <td>0.464428</td>\n      <td>0.416107</td>\n      <td>0.527146</td>\n      <td>0.576631</td>\n      <td>0.533931</td>\n      <td>0.475399</td>\n      <td>0.480954</td>\n      <td>0.482409</td>\n      <td>0.536919</td>\n      <td>0.366169</td>\n      <td>0.296888</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.686938</td>\n      <td>0.638466</td>\n      <td>0.584685</td>\n      <td>0.648318</td>\n      <td>0.715638</td>\n      <td>0.665114</td>\n      <td>0.635441</td>\n      <td>0.637042</td>\n      <td>0.659932</td>\n      <td>0.668569</td>\n      <td>0.672862</td>\n      <td>0.502768</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "trainDf = pd.read_csv (\"data/ML-CUP20-TR.csv\")\n",
    "\n",
    "# Normalize\n",
    "colnames=trainDf.columns.values\n",
    "trainDf=pd.DataFrame(minmax_scale(trainDf, feature_range=(0,1), axis=0))\n",
    "trainDf.columns=colnames\n",
    "trainDf.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=trainDf.values\n",
    "Xtot = dataset[:, 0:10]\n",
    "Ytot = dataset[:, 10:12]\n",
    "ytot = dataset[:, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset 60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_split = trainDf.sample(frac=0.6,random_state=200)\n",
    "second_split=trainDf.drop(first_split.index)\n",
    "trainset = first_split.to_numpy()\n",
    "testset = second_split.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = trainset[:, 0:10]\n",
    "Y = trainset[:, 10:12]  # Y1 and Y2 train\n",
    "y = trainset[:, 10]     # Y1 train\n",
    "yb = trainset[:, 11]    # Y2 \n",
    "\n",
    "Xtest= dataset[:, 0:10]\n",
    "Ytest = dataset[:, 10:12] # Y1 and Y2 test\n",
    "ytest= dataset[:, 10]     # Y1 test\n",
    "ybtest= dataset[:, 11]    # Y2 test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL DATA NEED TO CHANGE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring='neg_mean_squared_error'\n",
    "n_jobs=2\n",
    "modelname=\"Random Forest Regressor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dont change this tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsy1=[]\n",
    "gridsy2=[]\n",
    "result_list=[]\n",
    "\n",
    "grid_dict = {}\n",
    "\n",
    "gridindexcounter=0\n",
    "def safe_arange(start, stop, step):\n",
    "    return step * np.arange(start / step, stop / step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, None]"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "max_depth = [int(x) for x in np.linspace(10, 50, num = 11)]\n",
    "max_depth.append(None)\n",
    "max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[{'base_estimator__n_estimators': [80, 110, 140, 170, 200], 'base_estimator__max_depth': [10, 32, 55, 77, 100, None], 'base_estimator__max_features': ['sqrt', 'auto'], 'base_estimator__min_samples_split': [2, 5, 10], 'base_estimator__min_samples_leaf': [1, 2, 4], 'base_estimator__bootstrap': [True, False]}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = n_estimators = [int(x) for x in np.linspace(start = 80, stop = 200, num = 5)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 100, num = 5)]\n",
    "max_depth.append(None)\n",
    "\n",
    "\n",
    "grid_params = [{\n",
    "          'base_estimator__n_estimators': n_estimators, #RandomForest Regressor\n",
    "          'base_estimator__max_depth':max_depth,\n",
    "          'base_estimator__max_features':['sqrt','auto'],\n",
    "          'base_estimator__min_samples_split':[2, 5, 10],\n",
    "          'base_estimator__min_samples_leaf':[1, 2, 4],\n",
    "          'base_estimator__bootstrap':[True, False]}]\n",
    "\n",
    "\n",
    "print(grid_params)\n",
    "pipe= Pipeline([('scl', StandardScaler()), ('base_estimator', RandomForestRegressor(max_depth=75))])\n",
    "\t\t\n",
    "gsY1 = GridSearchCV(estimator=pipe,\n",
    "\t\t\tparam_grid=grid_params,\n",
    "            n_jobs=n_jobs,\n",
    "\t\t\tscoring=scoring,\n",
    "\t\t\tcv=10,  verbose =1)\n",
    "gsY2 = GridSearchCV(estimator=pipe,\n",
    "\t\t\tparam_grid=grid_params,\n",
    "            n_jobs=n_jobs,\n",
    "\t\t\tscoring=scoring,\n",
    "\t\t\tcv=10, verbose =1)\n",
    "gridsy1.append(gsY1)  \n",
    "gridsy2.append(gsY2)  \n",
    "grid_dict[gridindexcounter]=modelname\n",
    "gridindexcounter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Performing model optimizations...\n",
      "\n",
      "Estimator: Random Forest Regressor\n",
      "Fitting 10 folds for each of 1080 candidates, totalling 10800 fits\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   21.2s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=2)]: Done 446 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=2)]: Done 796 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=2)]: Done 1246 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=2)]: Done 1796 tasks      | elapsed: 15.2min\n",
      "[Parallel(n_jobs=2)]: Done 2446 tasks      | elapsed: 20.3min\n",
      "[Parallel(n_jobs=2)]: Done 3196 tasks      | elapsed: 26.4min\n",
      "[Parallel(n_jobs=2)]: Done 4046 tasks      | elapsed: 34.2min\n",
      "[Parallel(n_jobs=2)]: Done 4996 tasks      | elapsed: 43.4min\n",
      "[Parallel(n_jobs=2)]: Done 6046 tasks      | elapsed: 54.7min\n",
      "[Parallel(n_jobs=2)]: Done 7196 tasks      | elapsed: 68.3min\n",
      "[Parallel(n_jobs=2)]: Done 8446 tasks      | elapsed: 83.7min\n",
      "[Parallel(n_jobs=2)]: Done 9796 tasks      | elapsed: 100.5min\n",
      "[Parallel(n_jobs=2)]: Done 10800 out of 10800 | elapsed: 112.4min finished\n",
      "\n",
      " Time taken: 1 hours 52 minutes and 24.44 seconds.\n",
      "Best params: {'base_estimator__bootstrap': False, 'base_estimator__max_depth': 32, 'base_estimator__max_features': 'sqrt', 'base_estimator__min_samples_leaf': 1, 'base_estimator__min_samples_split': 2, 'base_estimator__n_estimators': 170}\n",
      "Best training accuracy: -0.002\n",
      "Test set accuracy score for best params: 0.001 \n",
      "\n",
      "Estimator: Random Forest Regressor\n",
      "Fitting 10 folds for each of 1080 candidates, totalling 10800 fits\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=2)]: Done 446 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=2)]: Done 796 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=2)]: Done 1246 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=2)]: Done 1796 tasks      | elapsed: 14.1min\n",
      "[Parallel(n_jobs=2)]: Done 2446 tasks      | elapsed: 19.0min\n",
      "[Parallel(n_jobs=2)]: Done 3196 tasks      | elapsed: 25.5min\n",
      "[Parallel(n_jobs=2)]: Done 4046 tasks      | elapsed: 33.3min\n",
      "[Parallel(n_jobs=2)]: Done 4996 tasks      | elapsed: 40.7min\n",
      "[Parallel(n_jobs=2)]: Done 6046 tasks      | elapsed: 47.2min\n",
      "[Parallel(n_jobs=2)]: Done 7196 tasks      | elapsed: 58.3min\n",
      "[Parallel(n_jobs=2)]: Done 8446 tasks      | elapsed: 67.1min\n",
      "[Parallel(n_jobs=2)]: Done 9796 tasks      | elapsed: 83.3min\n",
      "[Parallel(n_jobs=2)]: Done 10800 out of 10800 | elapsed: 95.7min finished\n",
      "\n",
      " Time taken: 1 hours 35 minutes and 42.26 seconds.\n",
      "Best params: {'base_estimator__bootstrap': True, 'base_estimator__max_depth': 55, 'base_estimator__max_features': 'sqrt', 'base_estimator__min_samples_leaf': 1, 'base_estimator__min_samples_split': 2, 'base_estimator__n_estimators': 200}\n",
      "Best training accuracy: -0.007\n",
      "Test set accuracy score for best params: 0.004 \n"
     ]
    }
   ],
   "source": [
    "print('Performing model optimizations...')\n",
    "best_acc = 0.0\n",
    "best_clf = 0\n",
    "best_gs = ''\n",
    "\n",
    "for idx, gs in enumerate(gridsy1):\n",
    "    start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "    print('\\nEstimator: %s' % grid_dict[idx])\t\n",
    "    # Fit grid search\t\n",
    "    grid_result=gs.fit(X, y)\n",
    "    result_list.append(grid_result)\n",
    "    timer(start_time) # timing ends here for \"start_time\" variable\n",
    "    # Best params\n",
    "    print('Best params: %s' % gs.best_params_)\n",
    "    # Best training data accuracy\n",
    "    print('Best training accuracy: %.3f' % gs.best_score_)\n",
    "    # Predict on test data with best params\n",
    "    y_pred = gs.predict(Xtest)\n",
    "\n",
    "    # Test data accuracy of model with best params\n",
    "    print('Test set accuracy score for best params: %.3f ' % mean_squared_error(ytest, y_pred))\n",
    "    # Track best (highest test accuracy) model\n",
    "\n",
    "    if mean_squared_error(ytest, y_pred) > best_acc:\n",
    "        best_acc = mean_squared_error(ytest, y_pred)\n",
    "        best_gs = gs\n",
    "        best_clf = idx\n",
    "        \n",
    "best_acc = 0.0\n",
    "best_clf = 0\n",
    "best_gs = ''\n",
    "\n",
    "for idx, gs in enumerate(gridsy2):\n",
    "    start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "    print('\\nEstimator: %s' % grid_dict[idx])\t\n",
    "    # Fit grid search\t\n",
    "    grid_result=gs.fit(X, yb)\n",
    "    result_list.append(grid_result)\n",
    "    timer(start_time) # timing ends here for \"start_time\" variable\n",
    "    # Best params\n",
    "    print('Best params: %s' % gs.best_params_)\n",
    "    # Best training data accuracy\n",
    "    print('Best training accuracy: %.3f' % gs.best_score_)\n",
    "    # Predict on test data with best params\n",
    "    y_predb = gs.predict(Xtest)\n",
    "\n",
    "    # Test data accuracy of model with best params\n",
    "    print('Test set accuracy score for best params: %.3f ' % mean_squared_error(ybtest, y_predb))\n",
    "    # Track best (highest test accuracy) model\n",
    "\n",
    "    if mean_squared_error(ybtest, y_predb) > best_acc:\n",
    "        best_acc = mean_squared_error(ybtest, y_predb)\n",
    "        best_gs = gs\n",
    "        best_clf = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0350b8bce0a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mybtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_predb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "plt.scatter(ytest,ybtest)\n",
    "plt.scatter(y_pred,y_predb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}