{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Model Name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'enable_halving_search_cv' from 'sklearn.experimental' (C:\\ProgramData\\Anaconda3\\envs\\branch-env\\lib\\site-packages\\sklearn\\experimental\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-176cbc1da321>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRepeatedKFold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0menable_halving_search_cv\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHalvingGridSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'enable_halving_search_cv' from 'sklearn.experimental' (C:\\ProgramData\\Anaconda3\\envs\\branch-env\\lib\\site-packages\\sklearn\\experimental\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn.preprocessing import minmax_scale\n",
    "%matplotlib inline\n",
    "from scipy import stats\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from pandas import read_csv\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "import itertools \n",
    "from time import time\n",
    "from functools import reduce \n",
    "import operator\n",
    "\n",
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))\n",
    "\n",
    "#Seaborn\n",
    "import seaborn as sns #Visualization\n",
    "plt.rcParams['figure.figsize'] = [8,5]\n",
    "plt.rcParams['font.size'] =14\n",
    "plt.rcParams['font.weight']= 'bold'\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet # Import model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf = pd.read_csv (\"data/ML-CUP20-TR.csv\")\n",
    "\n",
    "# Normalize\n",
    "colnames=trainDf.columns.values\n",
    "trainDf=pd.DataFrame(minmax_scale(trainDf, feature_range=(0,1), axis=0))\n",
    "trainDf.columns=colnames\n",
    "trainDf.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=trainDf.values\n",
    "Xtot = dataset[:, 0:10]\n",
    "Ytot = dataset[:, 10:12]\n",
    "ytot = dataset[:, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset 60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_split = trainDf.sample(frac=0.6,random_state=200)\n",
    "second_split=trainDf.drop(first_split.index)\n",
    "trainset = first_split.to_numpy()\n",
    "testset = second_split.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = trainset[:, 0:10]\n",
    "Y = trainset[:, 10:12]  # Y1 and Y2 train\n",
    "y = trainset[:, 10]     # Y1 train\n",
    "yb = trainset[:, 11]    # Y2 \n",
    "\n",
    "Xtest= dataset[:, 0:10]\n",
    "Ytest = dataset[:, 10:12] # Y1 and Y2 test\n",
    "ytest= dataset[:, 10]     # Y1 test\n",
    "ybtest= dataset[:, 11]    # Y2 test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL DATA NEED TO CHANGE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring='neg_mean_squared_error'\n",
    "n_jobs=1\n",
    "modelname=\"Elastic Net\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dont change this tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsy1=[]\n",
    "gridsy2=[]\n",
    "result_list=[]\n",
    "\n",
    "grid_dict = {}\n",
    "\n",
    "gridindexcounter=0\n",
    "def safe_arange(start, stop, step):\n",
    "    return step * np.arange(start / step, stop / step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grid_params = [{'estimator__base_estimator__alpha':safe_arange(0.000001,0.00001,0.000001)}] \n",
    "\n",
    "print(grid_params)\n",
    "pipe= Pipeline([('scl', StandardScaler()), ('estimator__base_estimator', ElasticNet(random_state=42))])\n",
    "\t\t\n",
    "gsY1 = HalvingGridSearchCV(estimator=pipe,\n",
    "\t\t\tparam_grid=grid_params,\n",
    "            n_jobs=n_jobs,\n",
    "\t\t\tscoring=scoring,\n",
    "            factor=2,\n",
    "\t\t\tcv=10)\n",
    "gsY2 = HalvingGridSearchCV(estimator=pipe,\n",
    "\t\t\tparam_grid=grid_params,\n",
    "            n_jobs=n_jobs,\n",
    "            factor=2,\n",
    "\t\t\tscoring=scoring,\n",
    "\t\t\tcv=10)\n",
    "gridsy1.append(gsY1)  \n",
    "gridsy2.append(gsY2)  \n",
    "grid_dict[gridindexcounter]=modelname\n",
    "gridindexcounter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Performing model optimizations...')\n",
    "best_acc = 0.0\n",
    "best_clf = 0\n",
    "best_gs = ''\n",
    "\n",
    "for idx, gs in enumerate(gridsy1):\n",
    "    start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "    print('\\nEstimator: %s' % grid_dict[idx])\t\n",
    "    # Fit grid search\t\n",
    "    grid_result=gs.fit(X, y)\n",
    "    result_list.append(grid_result)\n",
    "    timer(start_time) # timing ends here for \"start_time\" variable\n",
    "    # Best params\n",
    "    print('Best params: %s' % gs.best_params_)\n",
    "    # Best training data accuracy\n",
    "    print('Best training accuracy: %.3f' % gs.best_score_)\n",
    "    # Predict on test data with best params\n",
    "    y_pred = gs.predict(Xtest)\n",
    "\n",
    "    # Test data accuracy of model with best params\n",
    "    print('Test set accuracy score for best params: %.3f ' % mean_squared_error(ytest, y_pred))\n",
    "    # Track best (highest test accuracy) model\n",
    "\n",
    "    if mean_squared_error(ytest, y_pred) > best_acc:\n",
    "        best_acc = mean_squared_error(ytest, y_pred)\n",
    "        best_gs = gs\n",
    "        best_clf = idx\n",
    "        \n",
    "best_acc = 0.0\n",
    "best_clf = 0\n",
    "best_gs = ''\n",
    "\n",
    "for idx, gs in enumerate(gridsy2):\n",
    "    start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "    print('\\nEstimator: %s' % grid_dict[idx])\t\n",
    "    # Fit grid search\t\n",
    "    grid_result=gs.fit(X, yb)\n",
    "    result_list.append(grid_result)\n",
    "    timer(start_time) # timing ends here for \"start_time\" variable\n",
    "    # Best params\n",
    "    print('Best params: %s' % gs.best_params_)\n",
    "    # Best training data accuracy\n",
    "    print('Best training accuracy: %.3f' % gs.best_score_)\n",
    "    # Predict on test data with best params\n",
    "    y_predb = gs.predict(Xtest)\n",
    "\n",
    "    # Test data accuracy of model with best params\n",
    "    print('Test set accuracy score for best params: %.3f ' % mean_squared_error(ybtest, y_predb))\n",
    "    # Track best (highest test accuracy) model\n",
    "\n",
    "    if mean_squared_error(ybtest, y_predb) > best_acc:\n",
    "        best_acc = mean_squared_error(ybtest, y_predb)\n",
    "        best_gs = gs\n",
    "        best_clf = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(ytest,ybtest)\n",
    "plt.scatter(y_pred,y_predb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
