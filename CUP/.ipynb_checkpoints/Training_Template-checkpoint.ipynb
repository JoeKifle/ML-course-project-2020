{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Model Name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn.preprocessing import minmax_scale\n",
    "%matplotlib inline\n",
    "from scipy import stats\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from pandas import read_csv\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "import itertools \n",
    "from time import time\n",
    "from functools import reduce \n",
    "import operator\n",
    "\n",
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))\n",
    "\n",
    "#Seaborn\n",
    "import seaborn as sns #Visualization\n",
    "plt.rcParams['figure.figsize'] = [8,5]\n",
    "plt.rcParams['font.size'] =14\n",
    "plt.rcParams['font.weight']= 'bold'\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet # Import model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1524.000000</td>\n",
       "      <td>1524.000000</td>\n",
       "      <td>1524.000000</td>\n",
       "      <td>1524.000000</td>\n",
       "      <td>1524.000000</td>\n",
       "      <td>1524.000000</td>\n",
       "      <td>1524.000000</td>\n",
       "      <td>1524.000000</td>\n",
       "      <td>1524.000000</td>\n",
       "      <td>1524.000000</td>\n",
       "      <td>1524.000000</td>\n",
       "      <td>1524.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.006309</td>\n",
       "      <td>0.020143</td>\n",
       "      <td>0.010106</td>\n",
       "      <td>0.003109</td>\n",
       "      <td>0.005619</td>\n",
       "      <td>0.023872</td>\n",
       "      <td>0.006110</td>\n",
       "      <td>-0.011253</td>\n",
       "      <td>0.007343</td>\n",
       "      <td>0.005921</td>\n",
       "      <td>48.474973</td>\n",
       "      <td>-28.571117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.041026</td>\n",
       "      <td>1.045854</td>\n",
       "      <td>1.040690</td>\n",
       "      <td>1.048153</td>\n",
       "      <td>1.026938</td>\n",
       "      <td>1.054734</td>\n",
       "      <td>1.051558</td>\n",
       "      <td>1.045984</td>\n",
       "      <td>1.034932</td>\n",
       "      <td>1.057754</td>\n",
       "      <td>15.218671</td>\n",
       "      <td>10.269957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.247241</td>\n",
       "      <td>-2.158406</td>\n",
       "      <td>-2.068117</td>\n",
       "      <td>-3.190003</td>\n",
       "      <td>-2.657307</td>\n",
       "      <td>-3.467126</td>\n",
       "      <td>-2.167943</td>\n",
       "      <td>-2.435643</td>\n",
       "      <td>-2.298636</td>\n",
       "      <td>-2.325151</td>\n",
       "      <td>25.978398</td>\n",
       "      <td>-41.864859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.987447</td>\n",
       "      <td>-0.909239</td>\n",
       "      <td>-0.907696</td>\n",
       "      <td>-0.749282</td>\n",
       "      <td>-0.920508</td>\n",
       "      <td>-0.658990</td>\n",
       "      <td>-0.983262</td>\n",
       "      <td>-0.893817</td>\n",
       "      <td>-0.939021</td>\n",
       "      <td>-0.972809</td>\n",
       "      <td>34.666957</td>\n",
       "      <td>-36.935725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.093405</td>\n",
       "      <td>0.062560</td>\n",
       "      <td>-0.023284</td>\n",
       "      <td>-0.030603</td>\n",
       "      <td>0.172423</td>\n",
       "      <td>-0.120652</td>\n",
       "      <td>0.136528</td>\n",
       "      <td>-0.005085</td>\n",
       "      <td>0.028914</td>\n",
       "      <td>0.208246</td>\n",
       "      <td>45.333403</td>\n",
       "      <td>-30.642449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.868999</td>\n",
       "      <td>0.894836</td>\n",
       "      <td>0.805138</td>\n",
       "      <td>0.695626</td>\n",
       "      <td>0.854577</td>\n",
       "      <td>0.701555</td>\n",
       "      <td>0.912320</td>\n",
       "      <td>0.783726</td>\n",
       "      <td>0.885435</td>\n",
       "      <td>0.829420</td>\n",
       "      <td>61.544593</td>\n",
       "      <td>-22.860160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.289184</td>\n",
       "      <td>2.623750</td>\n",
       "      <td>2.846079</td>\n",
       "      <td>2.803400</td>\n",
       "      <td>2.250039</td>\n",
       "      <td>2.800493</td>\n",
       "      <td>2.679499</td>\n",
       "      <td>2.617978</td>\n",
       "      <td>2.526212</td>\n",
       "      <td>2.393244</td>\n",
       "      <td>78.836480</td>\n",
       "      <td>-4.064733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                X1           X2           X3           X4           X5  \\\n",
       "count  1524.000000  1524.000000  1524.000000  1524.000000  1524.000000   \n",
       "mean     -0.006309     0.020143     0.010106     0.003109     0.005619   \n",
       "std       1.041026     1.045854     1.040690     1.048153     1.026938   \n",
       "min      -2.247241    -2.158406    -2.068117    -3.190003    -2.657307   \n",
       "25%      -0.987447    -0.909239    -0.907696    -0.749282    -0.920508   \n",
       "50%       0.093405     0.062560    -0.023284    -0.030603     0.172423   \n",
       "75%       0.868999     0.894836     0.805138     0.695626     0.854577   \n",
       "max       2.289184     2.623750     2.846079     2.803400     2.250039   \n",
       "\n",
       "                X6           X7           X8           X9          X10  \\\n",
       "count  1524.000000  1524.000000  1524.000000  1524.000000  1524.000000   \n",
       "mean      0.023872     0.006110    -0.011253     0.007343     0.005921   \n",
       "std       1.054734     1.051558     1.045984     1.034932     1.057754   \n",
       "min      -3.467126    -2.167943    -2.435643    -2.298636    -2.325151   \n",
       "25%      -0.658990    -0.983262    -0.893817    -0.939021    -0.972809   \n",
       "50%      -0.120652     0.136528    -0.005085     0.028914     0.208246   \n",
       "75%       0.701555     0.912320     0.783726     0.885435     0.829420   \n",
       "max       2.800493     2.679499     2.617978     2.526212     2.393244   \n",
       "\n",
       "                Y1           Y2  \n",
       "count  1524.000000  1524.000000  \n",
       "mean     48.474973   -28.571117  \n",
       "std      15.218671    10.269957  \n",
       "min      25.978398   -41.864859  \n",
       "25%      34.666957   -36.935725  \n",
       "50%      45.333403   -30.642449  \n",
       "75%      61.544593   -22.860160  \n",
       "max      78.836480    -4.064733  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDf = pd.read_csv (\"data/ML-CUP20-TR.csv\")\n",
    "trainDf.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=trainDf.values\n",
    "Xtot = dataset[:, 0:10]\n",
    "Ytot = dataset[:, 10:12]\n",
    "ytot = dataset[:, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset 60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_split = trainDf.sample(frac=0.6,random_state=200)\n",
    "second_split=trainDf.drop(first_split.index)\n",
    "trainset = first_split.to_numpy()\n",
    "testset = second_split.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = trainset[:, 0:10]\n",
    "Y = trainset[:, 10:12]  # Y1 and Y2 train\n",
    "y = trainset[:, 10]     # Y1 train\n",
    "yb = trainset[:, 11]    # Y2 \n",
    "\n",
    "Xtest= dataset[:, 0:10]\n",
    "Ytest = dataset[:, 10:12] # Y1 and Y2 test\n",
    "ytest= dataset[:, 10]     # Y1 test\n",
    "ybtest= dataset[:, 11]    # Y2 test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL DATA NEED TO CHANGE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring='neg_mean_squared_error'\n",
    "n_jobs=1\n",
    "modelname=\"Elastic Net\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dont change this tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsy1=[]\n",
    "gridsy2=[]\n",
    "result_list=[]\n",
    "\n",
    "grid_dict = {}\n",
    "\n",
    "gridindexcounter=0\n",
    "def safe_arange(start, stop, step):\n",
    "    return step * np.arange(start / step, stop / step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grid_params = [{'clf__alpha':safe_arange(0.1,1,0.1)}] \n",
    "\n",
    "pipe= Pipeline([('scl', StandardScaler()), ('clf', ElasticNet(random_state=42))])\n",
    "\t\t\n",
    "gsY1 = GridSearchCV(estimator=pipe,\n",
    "\t\t\tparam_grid=grid_params,\n",
    "            n_jobs=n_jobs,\n",
    "\t\t\tscoring=scoring,\n",
    "\t\t\tcv=10)\n",
    "gsY2 = GridSearchCV(estimator=pipe,\n",
    "\t\t\tparam_grid=grid_params,\n",
    "            n_jobs=n_jobs,\n",
    "\t\t\tscoring=scoring,\n",
    "\t\t\tcv=10)\n",
    "gridsy1.append(gsY1)  \n",
    "gridsy2.append(gsY2)  \n",
    "grid_dict[gridindexcounter]=modelname\n",
    "gridindexcounter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing model optimizations...\n",
      "\n",
      "Estimator: Elastic Net\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\branch-env\\lib\\site-packages\\sklearn\\pipeline.py:335: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\branch-env\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\branch-env\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7506.777482401031, tolerance: 18.535658059263348\n",
      "  positive)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\branch-env\\lib\\site-packages\\sklearn\\pipeline.py:335: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\branch-env\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\branch-env\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7569.32870169616, tolerance: 18.603046711145662\n",
      "  positive)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\branch-env\\lib\\site-packages\\sklearn\\pipeline.py:335: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\branch-env\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\branch-env\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7707.907018009397, tolerance: 18.69073719223877\n",
      "  positive)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\branch-env\\lib\\site-packages\\sklearn\\pipeline.py:335: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\branch-env\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\branch-env\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7463.011659179844, tolerance: 18.34530501686167\n",
      "  positive)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\branch-env\\lib\\site-packages\\sklearn\\pipeline.py:335: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\branch-env\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\branch-env\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7685.7217804884185, tolerance: 18.568301790371383\n",
      "  positive)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\branch-env\\lib\\site-packages\\sklearn\\pipeline.py:335: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\branch-env\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\branch-env\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7629.512623570589, tolerance: 18.501402100174836\n",
      "  positive)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\branch-env\\lib\\site-packages\\sklearn\\pipeline.py:335: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\branch-env\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\branch-env\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7761.074366864021, tolerance: 18.71555401090745\n",
      "  positive)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\branch-env\\lib\\site-packages\\sklearn\\pipeline.py:335: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\branch-env\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\branch-env\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7614.3890250833465, tolerance: 18.21606700031822\n",
      "  positive)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\branch-env\\lib\\site-packages\\sklearn\\pipeline.py:335: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\branch-env\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\branch-env\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7598.324361528469, tolerance: 18.529992945301647\n",
      "  positive)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\branch-env\\lib\\site-packages\\sklearn\\pipeline.py:335: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\branch-env\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\branch-env\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7708.589729643978, tolerance: 18.43414869894874\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Time taken: 0 hours 0 minutes and 0.8 seconds.\n",
      "Best params: {'clf__alpha': 0.0}\n",
      "Best training accuracy: -19.113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\branch-env\\lib\\site-packages\\sklearn\\pipeline.py:335: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\branch-env\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\branch-env\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8484.807126084286, tolerance: 20.57199631283132\n",
      "  positive)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mean_squared_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-d1d208a3bd4c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m# Test data accuracy of model with best params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test set accuracy score for best params: %.3f '\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[1;31m# Track best (highest test accuracy) model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mean_squared_error' is not defined"
     ]
    }
   ],
   "source": [
    "print('Performing model optimizations...')\n",
    "best_acc = 0.0\n",
    "best_clf = 0\n",
    "best_gs = ''\n",
    "\n",
    "for idx, gs in enumerate(gridsy1):\n",
    "    start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "    print('\\nEstimator: %s' % grid_dict[idx])\t\n",
    "    # Fit grid search\t\n",
    "    grid_result=gs.fit(X, y)\n",
    "    result_list.append(grid_result)\n",
    "    timer(start_time) # timing ends here for \"start_time\" variable\n",
    "    # Best params\n",
    "    print('Best params: %s' % gs.best_params_)\n",
    "    # Best training data accuracy\n",
    "    print('Best training accuracy: %.3f' % gs.best_score_)\n",
    "    # Predict on test data with best params\n",
    "    y_pred = gs.predict(X)\n",
    "\n",
    "    # Test data accuracy of model with best params\n",
    "    print('Test set accuracy score for best params: %.3f ' % mean_squared_error(y, y_pred))\n",
    "    # Track best (highest test accuracy) model\n",
    "\n",
    "    if mean_squared_error(y, y_pred) > best_acc:\n",
    "        best_acc = mean_squared_error(y, y_pred)\n",
    "        best_gs = gs\n",
    "        best_clf = idx\n",
    "        \n",
    "best_acc = 0.0\n",
    "best_clf = 0\n",
    "best_gs = ''\n",
    "\n",
    "for idx, gs in enumerate(gridsy2):\n",
    "    start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "    print('\\nEstimator: %s' % grid_dict[idx])\t\n",
    "    # Fit grid search\t\n",
    "    grid_result=gs.fit(X, y)\n",
    "    result_list.append(grid_result)\n",
    "    timer(start_time) # timing ends here for \"start_time\" variable\n",
    "    # Best params\n",
    "    print('Best params: %s' % gs.best_params_)\n",
    "    # Best training data accuracy\n",
    "    print('Best training accuracy: %.3f' % gs.best_score_)\n",
    "    # Predict on test data with best params\n",
    "    y_pred = gs.predict(X)\n",
    "\n",
    "    # Test data accuracy of model with best params\n",
    "    print('Test set accuracy score for best params: %.3f ' % mean_squared_error(y, y_pred))\n",
    "    # Track best (highest test accuracy) model\n",
    "\n",
    "    if mean_squared_error(y, y_pred) > best_acc:\n",
    "        best_acc = mean_squared_error(y, y_pred)\n",
    "        best_gs = gs\n",
    "        best_clf = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1= ElasticNet(random_state=42)\n",
    "history1 = model1.fit(Xtrain, ytrain, epochs=150, batch_size=5,  verbose=1, validation_split=0.3)\n",
    "print(history1.history[\"mae\"][-1])\n",
    "print(history1.history[\"val_mae\"][-1])\n",
    "plt.plot(history1.history['loss'])\n",
    "plt.plot(history1.history['val_loss'])\n",
    "plt.title('model loss and accuracy')\n",
    "plt.ylabel('loss/accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss', 'validation_loss'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "model1.score(Xtest,ytest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
