{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "# for combining all the hyper-parameters\n",
    "import itertools \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for the best parameter\n",
    "g_eta = [0.1,0.2,0.3]\n",
    "g_batchSize = [10,20,25,30]\n",
    "g_hiddeLayerunit1 = [4,8,10]\n",
    "g_momentum = [0.6,0.8,0.9]\n",
    "g_afHiddenLayerunit1 = [\"relu\", \"tanh\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading training and testing data from the csv file\n",
    "trainDf = pd.read_csv ('data/csv/monks-2Train.csv',header=None).to_numpy()\n",
    "testDf = pd.read_csv ('data/csv/monks-2Test.csv',header=None).to_numpy()\n",
    "trainDf = minmax_scale(trainDf, feature_range=(0,1), axis=0)\n",
    "testDf = minmax_scale(trainDf, feature_range=(0,1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing trainDf for training\n",
    "trainX = trainDf[:, 1:7]\n",
    "trainY = trainDf[:, 0]\n",
    "#trainX = scaler.fit_transform(trainX)\n",
    "#trainY = scaler.fit_transform(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing testDf for validation\n",
    "testX = testDf[:, 1:7]\n",
    "testY = testDf[:, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All combination of the hyper-paramers\n",
    "gridParameters=[g_eta,g_batchSize,g_hiddeLayerunit1,g_momentum,g_afHiddenLayerunit1]\n",
    "allcombination = list(itertools.product(*gridParameters))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the grid search I was able to get the best hyperparameters\n",
    "eta = 0.1\n",
    "batch size = 10\n",
    "hiddenLayer = 10\n",
    "momentum = 0.7\n",
    "hiddenLayer af = relu\n",
    "\n",
    "(0.1, 10, 10, 0.9, 'relu') - Then added a new hidden layer with activation unit of tanh and get accuracy of 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "17/17 - 0s - loss: 0.2541 - accuracy: 0.5385 - val_loss: 0.2539 - val_accuracy: 0.6213\n",
      "Epoch 2/120\n",
      "17/17 - 0s - loss: 0.2392 - accuracy: 0.6213 - val_loss: 0.2303 - val_accuracy: 0.6213\n",
      "Epoch 3/120\n",
      "17/17 - 0s - loss: 0.2389 - accuracy: 0.6272 - val_loss: 0.2283 - val_accuracy: 0.6213\n",
      "Epoch 4/120\n",
      "17/17 - 0s - loss: 0.2338 - accuracy: 0.6213 - val_loss: 0.2257 - val_accuracy: 0.6213\n",
      "Epoch 5/120\n",
      "17/17 - 0s - loss: 0.2337 - accuracy: 0.6095 - val_loss: 0.2221 - val_accuracy: 0.6213\n",
      "Epoch 6/120\n",
      "17/17 - 0s - loss: 0.2254 - accuracy: 0.6272 - val_loss: 0.2173 - val_accuracy: 0.6627\n",
      "Epoch 7/120\n",
      "17/17 - 0s - loss: 0.2205 - accuracy: 0.6450 - val_loss: 0.2117 - val_accuracy: 0.6568\n",
      "Epoch 8/120\n",
      "17/17 - 0s - loss: 0.2125 - accuracy: 0.6509 - val_loss: 0.2040 - val_accuracy: 0.6746\n",
      "Epoch 9/120\n",
      "17/17 - 0s - loss: 0.2055 - accuracy: 0.6805 - val_loss: 0.1978 - val_accuracy: 0.7101\n",
      "Epoch 10/120\n",
      "17/17 - 0s - loss: 0.1964 - accuracy: 0.6923 - val_loss: 0.1919 - val_accuracy: 0.6923\n",
      "Epoch 11/120\n",
      "17/17 - 0s - loss: 0.1989 - accuracy: 0.6805 - val_loss: 0.1795 - val_accuracy: 0.7278\n",
      "Epoch 12/120\n",
      "17/17 - 0s - loss: 0.1812 - accuracy: 0.7456 - val_loss: 0.1728 - val_accuracy: 0.7929\n",
      "Epoch 13/120\n",
      "17/17 - 0s - loss: 0.1828 - accuracy: 0.7574 - val_loss: 0.1651 - val_accuracy: 0.7633\n",
      "Epoch 14/120\n",
      "17/17 - 0s - loss: 0.1643 - accuracy: 0.7751 - val_loss: 0.1559 - val_accuracy: 0.8047\n",
      "Epoch 15/120\n",
      "17/17 - 0s - loss: 0.1715 - accuracy: 0.7515 - val_loss: 0.1680 - val_accuracy: 0.7692\n",
      "Epoch 16/120\n",
      "17/17 - 0s - loss: 0.1669 - accuracy: 0.7811 - val_loss: 0.1512 - val_accuracy: 0.7988\n",
      "Epoch 17/120\n",
      "17/17 - 0s - loss: 0.1636 - accuracy: 0.7870 - val_loss: 0.1481 - val_accuracy: 0.7929\n",
      "Epoch 18/120\n",
      "17/17 - 0s - loss: 0.1663 - accuracy: 0.7988 - val_loss: 0.1815 - val_accuracy: 0.7278\n",
      "Epoch 19/120\n",
      "17/17 - 0s - loss: 0.1701 - accuracy: 0.7811 - val_loss: 0.1353 - val_accuracy: 0.8107\n",
      "Epoch 20/120\n",
      "17/17 - 0s - loss: 0.1472 - accuracy: 0.7811 - val_loss: 0.1396 - val_accuracy: 0.8284\n",
      "Epoch 21/120\n",
      "17/17 - 0s - loss: 0.1481 - accuracy: 0.7692 - val_loss: 0.1275 - val_accuracy: 0.8521\n",
      "Epoch 22/120\n",
      "17/17 - 0s - loss: 0.1578 - accuracy: 0.7751 - val_loss: 0.1736 - val_accuracy: 0.7456\n",
      "Epoch 23/120\n",
      "17/17 - 0s - loss: 0.1639 - accuracy: 0.7574 - val_loss: 0.1633 - val_accuracy: 0.7751\n",
      "Epoch 24/120\n",
      "17/17 - 0s - loss: 0.1678 - accuracy: 0.7456 - val_loss: 0.1589 - val_accuracy: 0.7751\n",
      "Epoch 25/120\n",
      "17/17 - 0s - loss: 0.1812 - accuracy: 0.7278 - val_loss: 0.1326 - val_accuracy: 0.8166\n",
      "Epoch 26/120\n",
      "17/17 - 0s - loss: 0.1558 - accuracy: 0.7929 - val_loss: 0.1366 - val_accuracy: 0.7929\n",
      "Epoch 27/120\n",
      "17/17 - 0s - loss: 0.1289 - accuracy: 0.8166 - val_loss: 0.1646 - val_accuracy: 0.7811\n",
      "Epoch 28/120\n",
      "17/17 - 0s - loss: 0.1288 - accuracy: 0.8225 - val_loss: 0.1271 - val_accuracy: 0.8343\n",
      "Epoch 29/120\n",
      "17/17 - 0s - loss: 0.1258 - accuracy: 0.8580 - val_loss: 0.1118 - val_accuracy: 0.8639\n",
      "Epoch 30/120\n",
      "17/17 - 0s - loss: 0.1238 - accuracy: 0.8580 - val_loss: 0.1114 - val_accuracy: 0.8698\n",
      "Epoch 31/120\n",
      "17/17 - 0s - loss: 0.1137 - accuracy: 0.8757 - val_loss: 0.1131 - val_accuracy: 0.8284\n",
      "Epoch 32/120\n",
      "17/17 - 0s - loss: 0.1345 - accuracy: 0.8166 - val_loss: 0.1140 - val_accuracy: 0.8580\n",
      "Epoch 33/120\n",
      "17/17 - 0s - loss: 0.1169 - accuracy: 0.8521 - val_loss: 0.1124 - val_accuracy: 0.8580\n",
      "Epoch 34/120\n",
      "17/17 - 0s - loss: 0.1181 - accuracy: 0.8402 - val_loss: 0.1014 - val_accuracy: 0.8935\n",
      "Epoch 35/120\n",
      "17/17 - 0s - loss: 0.1226 - accuracy: 0.8284 - val_loss: 0.1429 - val_accuracy: 0.7811\n",
      "Epoch 36/120\n",
      "17/17 - 0s - loss: 0.1354 - accuracy: 0.8047 - val_loss: 0.1258 - val_accuracy: 0.8225\n",
      "Epoch 37/120\n",
      "17/17 - 0s - loss: 0.1130 - accuracy: 0.8639 - val_loss: 0.1044 - val_accuracy: 0.8757\n",
      "Epoch 38/120\n",
      "17/17 - 0s - loss: 0.1299 - accuracy: 0.8343 - val_loss: 0.1362 - val_accuracy: 0.8343\n",
      "Epoch 39/120\n",
      "17/17 - 0s - loss: 0.1195 - accuracy: 0.8580 - val_loss: 0.0883 - val_accuracy: 0.9172\n",
      "Epoch 40/120\n",
      "17/17 - 0s - loss: 0.0962 - accuracy: 0.8817 - val_loss: 0.0925 - val_accuracy: 0.9053\n",
      "Epoch 41/120\n",
      "17/17 - 0s - loss: 0.1058 - accuracy: 0.8757 - val_loss: 0.0862 - val_accuracy: 0.8994\n",
      "Epoch 42/120\n",
      "17/17 - 0s - loss: 0.1092 - accuracy: 0.8757 - val_loss: 0.0981 - val_accuracy: 0.8757\n",
      "Epoch 43/120\n",
      "17/17 - 0s - loss: 0.1091 - accuracy: 0.8580 - val_loss: 0.0811 - val_accuracy: 0.9172\n",
      "Epoch 44/120\n",
      "17/17 - 0s - loss: 0.1001 - accuracy: 0.8698 - val_loss: 0.0858 - val_accuracy: 0.9053\n",
      "Epoch 45/120\n",
      "17/17 - 0s - loss: 0.0859 - accuracy: 0.9172 - val_loss: 0.0797 - val_accuracy: 0.8994\n",
      "Epoch 46/120\n",
      "17/17 - 0s - loss: 0.0938 - accuracy: 0.8817 - val_loss: 0.0771 - val_accuracy: 0.9053\n",
      "Epoch 47/120\n",
      "17/17 - 0s - loss: 0.0942 - accuracy: 0.8757 - val_loss: 0.0962 - val_accuracy: 0.8817\n",
      "Epoch 48/120\n",
      "17/17 - 0s - loss: 0.0784 - accuracy: 0.8935 - val_loss: 0.0671 - val_accuracy: 0.9290\n",
      "Epoch 49/120\n",
      "17/17 - 0s - loss: 0.0689 - accuracy: 0.9290 - val_loss: 0.0615 - val_accuracy: 0.9408\n",
      "Epoch 50/120\n",
      "17/17 - 0s - loss: 0.0709 - accuracy: 0.9349 - val_loss: 0.0627 - val_accuracy: 0.9231\n",
      "Epoch 51/120\n",
      "17/17 - 0s - loss: 0.0652 - accuracy: 0.9231 - val_loss: 0.0546 - val_accuracy: 0.9408\n",
      "Epoch 52/120\n",
      "17/17 - 0s - loss: 0.0556 - accuracy: 0.9467 - val_loss: 0.0507 - val_accuracy: 0.9467\n",
      "Epoch 53/120\n",
      "17/17 - 0s - loss: 0.0549 - accuracy: 0.9467 - val_loss: 0.0463 - val_accuracy: 0.9527\n",
      "Epoch 54/120\n",
      "17/17 - 0s - loss: 0.0601 - accuracy: 0.9231 - val_loss: 0.0458 - val_accuracy: 0.9527\n",
      "Epoch 55/120\n",
      "17/17 - 0s - loss: 0.0516 - accuracy: 0.9349 - val_loss: 0.0483 - val_accuracy: 0.9467\n",
      "Epoch 56/120\n",
      "17/17 - 0s - loss: 0.0491 - accuracy: 0.9467 - val_loss: 0.0407 - val_accuracy: 0.9527\n",
      "Epoch 57/120\n",
      "17/17 - 0s - loss: 0.0429 - accuracy: 0.9527 - val_loss: 0.0390 - val_accuracy: 0.9527\n",
      "Epoch 58/120\n",
      "17/17 - 0s - loss: 0.0412 - accuracy: 0.9467 - val_loss: 0.0346 - val_accuracy: 0.9586\n",
      "Epoch 59/120\n",
      "17/17 - 0s - loss: 0.0396 - accuracy: 0.9467 - val_loss: 0.0358 - val_accuracy: 0.9467\n",
      "Epoch 60/120\n",
      "17/17 - 0s - loss: 0.0374 - accuracy: 0.9408 - val_loss: 0.0377 - val_accuracy: 0.9704\n",
      "Epoch 61/120\n",
      "17/17 - 0s - loss: 0.0357 - accuracy: 0.9704 - val_loss: 0.0328 - val_accuracy: 0.9704\n",
      "Epoch 62/120\n",
      "17/17 - 0s - loss: 0.0318 - accuracy: 0.9763 - val_loss: 0.0272 - val_accuracy: 0.9822\n",
      "Epoch 63/120\n",
      "17/17 - 0s - loss: 0.0368 - accuracy: 0.9586 - val_loss: 0.0647 - val_accuracy: 0.8994\n",
      "Epoch 64/120\n",
      "17/17 - 0s - loss: 0.0393 - accuracy: 0.9645 - val_loss: 0.0368 - val_accuracy: 0.9586\n",
      "Epoch 65/120\n",
      "17/17 - 0s - loss: 0.0366 - accuracy: 0.9645 - val_loss: 0.0244 - val_accuracy: 0.9882\n",
      "Epoch 66/120\n",
      "17/17 - 0s - loss: 0.0262 - accuracy: 0.9822 - val_loss: 0.0238 - val_accuracy: 0.9882\n",
      "Epoch 67/120\n",
      "17/17 - 0s - loss: 0.0261 - accuracy: 0.9822 - val_loss: 0.0224 - val_accuracy: 0.9882\n",
      "Epoch 68/120\n",
      "17/17 - 0s - loss: 0.0285 - accuracy: 0.9763 - val_loss: 0.0284 - val_accuracy: 0.9763\n",
      "Epoch 69/120\n",
      "17/17 - 0s - loss: 0.0410 - accuracy: 0.9527 - val_loss: 0.0215 - val_accuracy: 0.9822\n",
      "Epoch 70/120\n",
      "17/17 - 0s - loss: 0.0281 - accuracy: 0.9704 - val_loss: 0.0219 - val_accuracy: 0.9882\n",
      "Epoch 71/120\n",
      "17/17 - 0s - loss: 0.0216 - accuracy: 0.9882 - val_loss: 0.0219 - val_accuracy: 0.9822\n",
      "Epoch 72/120\n",
      "17/17 - 0s - loss: 0.0216 - accuracy: 0.9882 - val_loss: 0.0239 - val_accuracy: 0.9763\n",
      "Epoch 73/120\n",
      "17/17 - 0s - loss: 0.0242 - accuracy: 0.9704 - val_loss: 0.0194 - val_accuracy: 0.9822\n",
      "Epoch 74/120\n",
      "17/17 - 0s - loss: 0.0254 - accuracy: 0.9822 - val_loss: 0.0180 - val_accuracy: 0.9941\n",
      "Epoch 75/120\n",
      "17/17 - 0s - loss: 0.0179 - accuracy: 0.9941 - val_loss: 0.0150 - val_accuracy: 0.9941\n",
      "Epoch 76/120\n",
      "17/17 - 0s - loss: 0.0171 - accuracy: 0.9882 - val_loss: 0.0131 - val_accuracy: 0.9882\n",
      "Epoch 77/120\n",
      "17/17 - 0s - loss: 0.0154 - accuracy: 0.9882 - val_loss: 0.0130 - val_accuracy: 0.9882\n",
      "Epoch 78/120\n",
      "17/17 - 0s - loss: 0.0145 - accuracy: 0.9941 - val_loss: 0.0126 - val_accuracy: 0.9941\n",
      "Epoch 79/120\n",
      "17/17 - 0s - loss: 0.0187 - accuracy: 0.9763 - val_loss: 0.0290 - val_accuracy: 0.9645\n",
      "Epoch 80/120\n",
      "17/17 - 0s - loss: 0.0219 - accuracy: 0.9704 - val_loss: 0.0229 - val_accuracy: 0.9822\n",
      "Epoch 81/120\n",
      "17/17 - 0s - loss: 0.0391 - accuracy: 0.9467 - val_loss: 0.0269 - val_accuracy: 0.9822\n",
      "Epoch 82/120\n",
      "17/17 - 0s - loss: 0.0454 - accuracy: 0.9408 - val_loss: 0.0236 - val_accuracy: 0.9763\n",
      "Epoch 83/120\n",
      "17/17 - 0s - loss: 0.0171 - accuracy: 0.9822 - val_loss: 0.0127 - val_accuracy: 0.9941\n",
      "Epoch 84/120\n",
      "17/17 - 0s - loss: 0.0270 - accuracy: 0.9704 - val_loss: 0.0321 - val_accuracy: 0.9586\n",
      "Epoch 85/120\n",
      "17/17 - 0s - loss: 0.0415 - accuracy: 0.9586 - val_loss: 0.0164 - val_accuracy: 0.9882\n",
      "Epoch 86/120\n",
      "17/17 - 0s - loss: 0.0316 - accuracy: 0.9645 - val_loss: 0.0194 - val_accuracy: 0.9822\n",
      "Epoch 87/120\n",
      "17/17 - 0s - loss: 0.0422 - accuracy: 0.9527 - val_loss: 0.0168 - val_accuracy: 0.9882\n",
      "Epoch 88/120\n",
      "17/17 - 0s - loss: 0.0372 - accuracy: 0.9408 - val_loss: 0.0117 - val_accuracy: 0.9941\n",
      "Epoch 89/120\n",
      "17/17 - 0s - loss: 0.0168 - accuracy: 0.9822 - val_loss: 0.0196 - val_accuracy: 0.9822\n",
      "Epoch 90/120\n",
      "17/17 - 0s - loss: 0.0258 - accuracy: 0.9704 - val_loss: 0.0095 - val_accuracy: 0.9941\n",
      "Epoch 91/120\n",
      "17/17 - 0s - loss: 0.0134 - accuracy: 0.9882 - val_loss: 0.0065 - val_accuracy: 0.9941\n",
      "Epoch 92/120\n",
      "17/17 - 0s - loss: 0.0101 - accuracy: 0.9941 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 93/120\n",
      "17/17 - 0s - loss: 0.0103 - accuracy: 0.9941 - val_loss: 0.0136 - val_accuracy: 0.9882\n",
      "Epoch 94/120\n",
      "17/17 - 0s - loss: 0.0160 - accuracy: 0.9822 - val_loss: 0.0209 - val_accuracy: 0.9763\n",
      "Epoch 95/120\n",
      "17/17 - 0s - loss: 0.0277 - accuracy: 0.9704 - val_loss: 0.0139 - val_accuracy: 0.9941\n",
      "Epoch 96/120\n",
      "17/17 - 0s - loss: 0.0147 - accuracy: 0.9822 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
      "Epoch 97/120\n",
      "17/17 - 0s - loss: 0.0093 - accuracy: 0.9941 - val_loss: 0.0165 - val_accuracy: 0.9882\n",
      "Epoch 98/120\n",
      "17/17 - 0s - loss: 0.0129 - accuracy: 0.9941 - val_loss: 0.0144 - val_accuracy: 0.9822\n",
      "Epoch 99/120\n",
      "17/17 - 0s - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.0187 - val_accuracy: 0.9763\n",
      "Epoch 100/120\n",
      "17/17 - 0s - loss: 0.0096 - accuracy: 0.9882 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 101/120\n",
      "17/17 - 0s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 102/120\n",
      "17/17 - 0s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 103/120\n",
      "17/17 - 0s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 104/120\n",
      "17/17 - 0s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 105/120\n",
      "17/17 - 0s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 106/120\n",
      "17/17 - 0s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 107/120\n",
      "17/17 - 0s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 108/120\n",
      "17/17 - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 109/120\n",
      "17/17 - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 110/120\n",
      "17/17 - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 111/120\n",
      "17/17 - 0s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 112/120\n",
      "17/17 - 0s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 113/120\n",
      "17/17 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 114/120\n",
      "17/17 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 115/120\n",
      "17/17 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 116/120\n",
      "17/17 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 117/120\n",
      "17/17 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 118/120\n",
      "17/17 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 119/120\n",
      "17/17 - 0s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 120/120\n",
      "17/17 - 0s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "############### HYPER PARAMETER SEARCH#################################\n",
    "\n",
    "for param in allcombination:\n",
    "    print(param)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=6, activation='tanh'))\n",
    "    model.add(Dense(4,  activation='tanh'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    sgd = SGD(lr=0, momentum=0.9, decay = ??, nesterov=False)\n",
    "    model.compile(optimizer=sgd, loss='mean_squared_error',metrics=['accuracy'])\n",
    "    history = model.fit(trainX, trainY, validation_data=(testX, testY), epochs=120, batch_size=10, verbose=2)\n",
    "\n",
    "#########################################################################\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
