{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\giaco\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\giaco\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\giaco\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\giaco\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\giaco\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\giaco\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\giaco\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\giaco\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\giaco\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\giaco\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\giaco\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\giaco\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "# for combining all the hyper-parameters\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for the best parameter\n",
    "g_eta = [0.1,0.2,0.3]\n",
    "g_batchSize = [10,20,25,30]\n",
    "g_hiddeLayerunit1 = [4,8,10]\n",
    "g_momentum = [0.6,0.8,0.9]\n",
    "g_afHiddenLayerunit1 = [\"relu\", \"tanh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading training and testing data from the csv file\n",
    "trainDf = pd.read_csv ('data/csv/monks-3Train.csv',header=None).to_numpy()\n",
    "testDf = pd.read_csv ('data/csv/monks-3Test.csv',header=None).to_numpy()\n",
    "trainDf = minmax_scale(trainDf, feature_range=(0,1), axis=0)\n",
    "testDf = minmax_scale(trainDf, feature_range=(0,1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing trainDf for training\n",
    "trainX = trainDf[:, 1:7]\n",
    "trainY = trainDf[:, 0]\n",
    "#trainX = scaler.fit_transform(trainX)\n",
    "#trainY = scaler.fit_transform(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing testDf for validation\n",
    "testX = testDf[:, 1:7]\n",
    "testY = testDf[:, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All combination of the hyper-paramers\n",
    "gridParameters=[g_eta,g_batchSize,g_hiddeLayerunit1,g_momentum,g_afHiddenLayerunit1]\n",
    "allcombination = list(itertools.product(*gridParameters))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the grid search I was able to get the best hyperparameters\n",
    "eta = 0.1\n",
    "batch size = 10\n",
    "hiddenLayer = 10\n",
    "momentum = 0.7\n",
    "hiddenLayer af = relu\n",
    "\n",
    "(0.1, 10, 10, 0.9, 'relu') - Then added a new hidden layer with activation unit of tanh and get accuracy of 99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\giaco\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 122 samples, validate on 122 samples\n",
      "Epoch 1/80\n",
      " - 0s - loss: 0.2364 - accuracy: 0.5738 - val_loss: 0.2238 - val_accuracy: 0.6803\n",
      "Epoch 2/80\n",
      " - 0s - loss: 0.2254 - accuracy: 0.6066 - val_loss: 0.1945 - val_accuracy: 0.7951\n",
      "Epoch 3/80\n",
      " - 0s - loss: 0.1746 - accuracy: 0.7787 - val_loss: 0.1469 - val_accuracy: 0.7951\n",
      "Epoch 4/80\n",
      " - 0s - loss: 0.1380 - accuracy: 0.8115 - val_loss: 0.1236 - val_accuracy: 0.8443\n",
      "Epoch 5/80\n",
      " - 0s - loss: 0.1358 - accuracy: 0.8033 - val_loss: 0.1318 - val_accuracy: 0.8361\n",
      "Epoch 6/80\n",
      " - 0s - loss: 0.1379 - accuracy: 0.8115 - val_loss: 0.1560 - val_accuracy: 0.7623\n",
      "Epoch 7/80\n",
      " - 0s - loss: 0.1310 - accuracy: 0.8197 - val_loss: 0.1119 - val_accuracy: 0.8443\n",
      "Epoch 8/80\n",
      " - 0s - loss: 0.1312 - accuracy: 0.8033 - val_loss: 0.1265 - val_accuracy: 0.8197\n",
      "Epoch 9/80\n",
      " - 0s - loss: 0.1152 - accuracy: 0.8443 - val_loss: 0.1054 - val_accuracy: 0.8361\n",
      "Epoch 10/80\n",
      " - 0s - loss: 0.1059 - accuracy: 0.8525 - val_loss: 0.1032 - val_accuracy: 0.8607\n",
      "Epoch 11/80\n",
      " - 0s - loss: 0.1112 - accuracy: 0.8443 - val_loss: 0.1063 - val_accuracy: 0.8607\n",
      "Epoch 12/80\n",
      " - 0s - loss: 0.1121 - accuracy: 0.8443 - val_loss: 0.0969 - val_accuracy: 0.8689\n",
      "Epoch 13/80\n",
      " - 0s - loss: 0.1024 - accuracy: 0.8689 - val_loss: 0.0977 - val_accuracy: 0.8689\n",
      "Epoch 14/80\n",
      " - 0s - loss: 0.1164 - accuracy: 0.8033 - val_loss: 0.1068 - val_accuracy: 0.8361\n",
      "Epoch 15/80\n",
      " - 0s - loss: 0.0910 - accuracy: 0.8770 - val_loss: 0.1145 - val_accuracy: 0.8197\n",
      "Epoch 16/80\n",
      " - 0s - loss: 0.1065 - accuracy: 0.8361 - val_loss: 0.0884 - val_accuracy: 0.8852\n",
      "Epoch 17/80\n",
      " - 0s - loss: 0.0918 - accuracy: 0.8607 - val_loss: 0.0843 - val_accuracy: 0.8852\n",
      "Epoch 18/80\n",
      " - 0s - loss: 0.0857 - accuracy: 0.8934 - val_loss: 0.0712 - val_accuracy: 0.9098\n",
      "Epoch 19/80\n",
      " - 0s - loss: 0.0770 - accuracy: 0.9098 - val_loss: 0.0678 - val_accuracy: 0.9262\n",
      "Epoch 20/80\n",
      " - 0s - loss: 0.0671 - accuracy: 0.9180 - val_loss: 0.0604 - val_accuracy: 0.9262\n",
      "Epoch 21/80\n",
      " - 0s - loss: 0.0702 - accuracy: 0.9098 - val_loss: 0.0597 - val_accuracy: 0.9180\n",
      "Epoch 22/80\n",
      " - 0s - loss: 0.0645 - accuracy: 0.9016 - val_loss: 0.0527 - val_accuracy: 0.9180\n",
      "Epoch 23/80\n",
      " - 0s - loss: 0.0598 - accuracy: 0.9262 - val_loss: 0.0516 - val_accuracy: 0.9180\n",
      "Epoch 24/80\n",
      " - 0s - loss: 0.0623 - accuracy: 0.9016 - val_loss: 0.0458 - val_accuracy: 0.9590\n",
      "Epoch 25/80\n",
      " - 0s - loss: 0.0558 - accuracy: 0.9262 - val_loss: 0.0431 - val_accuracy: 0.9426\n",
      "Epoch 26/80\n",
      " - 0s - loss: 0.0457 - accuracy: 0.9590 - val_loss: 0.0410 - val_accuracy: 0.9672\n",
      "Epoch 27/80\n",
      " - 0s - loss: 0.0497 - accuracy: 0.9262 - val_loss: 0.0434 - val_accuracy: 0.9426\n",
      "Epoch 28/80\n",
      " - 0s - loss: 0.0515 - accuracy: 0.9344 - val_loss: 0.0425 - val_accuracy: 0.9590\n",
      "Epoch 29/80\n",
      " - 0s - loss: 0.0529 - accuracy: 0.9262 - val_loss: 0.0478 - val_accuracy: 0.9262\n",
      "Epoch 30/80\n",
      " - 0s - loss: 0.0488 - accuracy: 0.9344 - val_loss: 0.0363 - val_accuracy: 0.9590\n",
      "Epoch 31/80\n",
      " - 0s - loss: 0.0460 - accuracy: 0.9262 - val_loss: 0.0488 - val_accuracy: 0.9426\n",
      "Epoch 32/80\n",
      " - 0s - loss: 0.0464 - accuracy: 0.9344 - val_loss: 0.0284 - val_accuracy: 0.9672\n",
      "Epoch 33/80\n",
      " - 0s - loss: 0.0394 - accuracy: 0.9590 - val_loss: 0.0292 - val_accuracy: 0.9754\n",
      "Epoch 34/80\n",
      " - 0s - loss: 0.0545 - accuracy: 0.9262 - val_loss: 0.0626 - val_accuracy: 0.9098\n",
      "Epoch 35/80\n",
      " - 0s - loss: 0.0471 - accuracy: 0.9426 - val_loss: 0.0310 - val_accuracy: 0.9672\n",
      "Epoch 36/80\n",
      " - 0s - loss: 0.0341 - accuracy: 0.9672 - val_loss: 0.0328 - val_accuracy: 0.9672\n",
      "Epoch 37/80\n",
      " - 0s - loss: 0.0302 - accuracy: 0.9672 - val_loss: 0.0250 - val_accuracy: 0.9672\n",
      "Epoch 38/80\n",
      " - 0s - loss: 0.0360 - accuracy: 0.9590 - val_loss: 0.0315 - val_accuracy: 0.9672\n",
      "Epoch 39/80\n",
      " - 0s - loss: 0.0303 - accuracy: 0.9672 - val_loss: 0.0247 - val_accuracy: 0.9754\n",
      "Epoch 40/80\n",
      " - 0s - loss: 0.0223 - accuracy: 0.9836 - val_loss: 0.0369 - val_accuracy: 0.9672\n",
      "Epoch 41/80\n",
      " - 0s - loss: 0.0285 - accuracy: 0.9672 - val_loss: 0.0345 - val_accuracy: 0.9344\n",
      "Epoch 42/80\n",
      " - 0s - loss: 0.0225 - accuracy: 0.9754 - val_loss: 0.0278 - val_accuracy: 0.9754\n",
      "Epoch 43/80\n",
      " - 0s - loss: 0.0243 - accuracy: 0.9754 - val_loss: 0.0810 - val_accuracy: 0.8934\n",
      "Epoch 44/80\n",
      " - 0s - loss: 0.0512 - accuracy: 0.9180 - val_loss: 0.0190 - val_accuracy: 0.9754\n",
      "Epoch 45/80\n",
      " - 0s - loss: 0.0233 - accuracy: 0.9754 - val_loss: 0.0218 - val_accuracy: 0.9836\n",
      "Epoch 46/80\n",
      " - 0s - loss: 0.0223 - accuracy: 0.9754 - val_loss: 0.0175 - val_accuracy: 0.9836\n",
      "Epoch 47/80\n",
      " - 0s - loss: 0.0229 - accuracy: 0.9672 - val_loss: 0.0150 - val_accuracy: 0.9918\n",
      "Epoch 48/80\n",
      " - 0s - loss: 0.0186 - accuracy: 0.9836 - val_loss: 0.0163 - val_accuracy: 0.9836\n",
      "Epoch 49/80\n",
      " - 0s - loss: 0.0173 - accuracy: 0.9754 - val_loss: 0.0149 - val_accuracy: 0.9918\n",
      "Epoch 50/80\n",
      " - 0s - loss: 0.0142 - accuracy: 0.9918 - val_loss: 0.0159 - val_accuracy: 0.9836\n",
      "Epoch 51/80\n",
      " - 0s - loss: 0.0172 - accuracy: 0.9836 - val_loss: 0.0121 - val_accuracy: 0.9918\n",
      "Epoch 52/80\n",
      " - 0s - loss: 0.0143 - accuracy: 0.9918 - val_loss: 0.0123 - val_accuracy: 0.9918\n",
      "Epoch 53/80\n",
      " - 0s - loss: 0.0143 - accuracy: 0.9918 - val_loss: 0.0122 - val_accuracy: 0.9918\n",
      "Epoch 54/80\n",
      " - 0s - loss: 0.0149 - accuracy: 0.9918 - val_loss: 0.0116 - val_accuracy: 0.9918\n",
      "Epoch 55/80\n",
      " - 0s - loss: 0.0133 - accuracy: 0.9918 - val_loss: 0.0112 - val_accuracy: 0.9918\n",
      "Epoch 56/80\n",
      " - 0s - loss: 0.0124 - accuracy: 0.9918 - val_loss: 0.0112 - val_accuracy: 0.9918\n",
      "Epoch 57/80\n",
      " - 0s - loss: 0.0119 - accuracy: 0.9918 - val_loss: 0.0120 - val_accuracy: 0.9918\n",
      "Epoch 58/80\n",
      " - 0s - loss: 0.0125 - accuracy: 0.9918 - val_loss: 0.0105 - val_accuracy: 0.9918\n",
      "Epoch 59/80\n",
      " - 0s - loss: 0.0113 - accuracy: 0.9918 - val_loss: 0.0113 - val_accuracy: 0.9918\n",
      "Epoch 60/80\n",
      " - 0s - loss: 0.0200 - accuracy: 0.9836 - val_loss: 0.0171 - val_accuracy: 0.9918\n",
      "Epoch 61/80\n",
      " - 0s - loss: 0.0378 - accuracy: 0.9508 - val_loss: 0.0237 - val_accuracy: 0.9754\n",
      "Epoch 62/80\n",
      " - 0s - loss: 0.0257 - accuracy: 0.9754 - val_loss: 0.0205 - val_accuracy: 0.9672\n",
      "Epoch 63/80\n",
      " - 0s - loss: 0.0234 - accuracy: 0.9754 - val_loss: 0.0193 - val_accuracy: 0.9836\n",
      "Epoch 64/80\n",
      " - 0s - loss: 0.0167 - accuracy: 0.9836 - val_loss: 0.0192 - val_accuracy: 0.9754\n",
      "Epoch 65/80\n",
      " - 0s - loss: 0.0373 - accuracy: 0.9508 - val_loss: 0.0429 - val_accuracy: 0.9508\n",
      "Epoch 66/80\n",
      " - 0s - loss: 0.0337 - accuracy: 0.9590 - val_loss: 0.0170 - val_accuracy: 0.9836\n",
      "Epoch 67/80\n",
      " - 0s - loss: 0.0191 - accuracy: 0.9836 - val_loss: 0.0137 - val_accuracy: 0.9836\n",
      "Epoch 68/80\n",
      " - 0s - loss: 0.0158 - accuracy: 0.9754 - val_loss: 0.0124 - val_accuracy: 0.9918\n",
      "Epoch 69/80\n",
      " - 0s - loss: 0.0394 - accuracy: 0.9590 - val_loss: 0.0366 - val_accuracy: 0.9426\n",
      "Epoch 70/80\n",
      " - 0s - loss: 0.0242 - accuracy: 0.9590 - val_loss: 0.0122 - val_accuracy: 0.9918\n",
      "Epoch 71/80\n",
      " - 0s - loss: 0.0141 - accuracy: 0.9836 - val_loss: 0.0134 - val_accuracy: 0.9918\n",
      "Epoch 72/80\n",
      " - 0s - loss: 0.0139 - accuracy: 0.9918 - val_loss: 0.0152 - val_accuracy: 0.9836\n",
      "Epoch 73/80\n",
      " - 0s - loss: 0.0182 - accuracy: 0.9836 - val_loss: 0.0118 - val_accuracy: 0.9918\n",
      "Epoch 74/80\n",
      " - 0s - loss: 0.0115 - accuracy: 0.9918 - val_loss: 0.0098 - val_accuracy: 0.9918\n",
      "Epoch 75/80\n",
      " - 0s - loss: 0.0104 - accuracy: 0.9918 - val_loss: 0.0097 - val_accuracy: 0.9918\n",
      "Epoch 76/80\n",
      " - 0s - loss: 0.0100 - accuracy: 0.9918 - val_loss: 0.0093 - val_accuracy: 0.9918\n",
      "Epoch 77/80\n",
      " - 0s - loss: 0.0093 - accuracy: 0.9918 - val_loss: 0.0092 - val_accuracy: 0.9918\n",
      "Epoch 78/80\n",
      " - 0s - loss: 0.0093 - accuracy: 0.9918 - val_loss: 0.0091 - val_accuracy: 0.9918\n",
      "Epoch 79/80\n",
      " - 0s - loss: 0.0093 - accuracy: 0.9918 - val_loss: 0.0091 - val_accuracy: 0.9918\n",
      "Epoch 80/80\n",
      " - 0s - loss: 0.0096 - accuracy: 0.9918 - val_loss: 0.0091 - val_accuracy: 0.9918\n"
     ]
    }
   ],
   "source": [
    "############### HYPER PARAMETER SEARCH#################################\n",
    "\n",
    "#for param in allcombination:\n",
    "#    print(param)\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=6, activation='tanh'))\n",
    "model.add(Dense(4,  activation='tanh'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "sgd = SGD(lr=0.1, momentum=0.9, nesterov=False)\n",
    "model.compile(optimizer=sgd, loss='mean_squared_error',metrics=['accuracy'])\n",
    "history = model.fit(trainX, trainY, validation_data=(testX, testY), epochs=80, batch_size=10, verbose=2)\n",
    "\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
