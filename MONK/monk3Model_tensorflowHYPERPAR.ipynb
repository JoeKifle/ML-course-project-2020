{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f34b23ab10b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSGD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "#keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.model_selection import train_test_split \n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from tensorflow import keras\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "#################TRAINING PARAM\n",
    "verbose_level=0\n",
    "\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "import threading\n",
    "\n",
    "jobs=1\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from keras import Sequential\n",
    "from keras import regularizers\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# for combining all the hyper-parameters\n",
    "import itertools \n",
    "from time import time\n",
    "from functools import reduce \n",
    "import operator\n",
    "\n",
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))\n",
    "\n",
    "\n",
    "#jobs=1 #due to the low dimension of the dataset the single gpu version is slower, so I'm forcing it to the multi core version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "g_decay = [0.01] # more estimations can be added\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# HP_BATCH_SIZE = hp.HParam('batch_size', hp.Discrete([10, 20, 40, 60, 80, 100]))\n",
    "# HP_NUM_UNITS1 = hp.HParam('num_units1', hp.Discrete([4,8,16, 32]))\n",
    "# HP_NUM_UNITS2 = hp.HParam('num_units2', hp.Discrete([4,8,16, 32]))\n",
    "# HP_ACTIVATION1 = hp.HParam('activation1', hp.Discrete([\"relu\", \"tanh\",\"sigmoid\",\"softmax\"]))\n",
    "# HP_ACTIVATION2 = hp.HParam('activation2', hp.Discrete([\"relu\", \"tanh\",\"sigmoid\",\"softmax\"]))\n",
    "# HP_ACTIVATION3 = hp.HParam('activation3', hp.Discrete([\"relu\", \"tanh\",\"sigmoid\",\"softmax\"]))\n",
    "# HP_INIT = hp.HParam('init_mode', hp.Discrete(['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']))\n",
    "# HP_MOMENTUM = hp.HParam('momentum', hp.Discrete(np.arange(0.1, 0.9, 0.1).tolist()))\n",
    "# HP_LEARNING_RATE = hp.HParam('lr', hp.Discrete(np.arange(0.1, 0.9, 0.1).tolist()))\n",
    "# HP_DROPOUT1 = hp.HParam('dropout1', hp.Discrete(np.arange(0.1, 0.9, 0.1).tolist()))\n",
    "# HP_DROPOUT2 = hp.HParam('dropout2', hp.Discrete(np.arange(0.1, 0.9, 0.1).tolist()))\n",
    "# #HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "# HP_EPOCH = hp.HParam('epoch',hp.Discrete(range(50,250,50)))\n",
    "\n",
    "\n",
    "HP_BATCH_SIZE = hp.HParam('batch_size', hp.Discrete([5,10]))\n",
    "HP_NUM_UNITS1 = hp.HParam('num_units1', hp.Discrete([4,8]))\n",
    "HP_NUM_UNITS2 = hp.HParam('num_units2', hp.Discrete([4,8]))\n",
    "HP_ACTIVATION1 = hp.HParam('activation1', hp.Discrete([\"relu\", \"tanh\"]))\n",
    "HP_ACTIVATION2 = hp.HParam('activation2', hp.Discrete([\"relu\", \"tanh\"]))\n",
    "\n",
    "HP_ACTIVATION3 = hp.HParam('activation3', hp.Discrete([\"relu\", \"tanh\"]))\n",
    "HP_INIT = hp.HParam('init_mode', hp.Discrete(['uniform']))\n",
    "HP_MOMENTUM = hp.HParam('momentum', hp.Discrete(np.arange(0.1, 0.9, 0.5).tolist()))\n",
    "HP_LEARNING_RATE = hp.HParam('lr', hp.Discrete(np.arange(0.1, 0.9, 0.5).tolist()))\n",
    "HP_DROPOUT1 = hp.HParam('dropout1', hp.Discrete(np.arange(0.1, 0.9, 0.5).tolist()))\n",
    "HP_DROPOUT2 = hp.HParam('dropout2', hp.Discrete(np.arange(0.1, 0.9, 0.5).tolist()))\n",
    "#HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "HP_EPOCH = hp.HParam('epoch',hp.Discrete(range(150,250,100)))\n",
    "\n",
    "\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "  hp.hparams_config(\n",
    "    hparams=[\n",
    "        HP_BATCH_SIZE,\n",
    "        HP_NUM_UNITS1,\n",
    "        HP_NUM_UNITS2,\n",
    "        HP_ACTIVATION1,\n",
    "        HP_ACTIVATION2,\n",
    "        HP_ACTIVATION3,\n",
    "        HP_INIT,\n",
    "        HP_MOMENTUM,\n",
    "        HP_LEARNING_RATE,\n",
    "        #HP_OPTIMIZER,\n",
    "        HP_DROPOUT1,\n",
    "        HP_DROPOUT2,\n",
    "        HP_EPOCH\n",
    "    ],\n",
    "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "  )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gridParameters=[\n",
    "    HP_BATCH_SIZE.__getattribute__(\"domain\").__getattribute__(\"values\"),\n",
    "    HP_NUM_UNITS1.__getattribute__(\"domain\").__getattribute__(\"values\"),\n",
    "    HP_NUM_UNITS2.__getattribute__(\"domain\").__getattribute__(\"values\"),\n",
    "    HP_ACTIVATION1.__getattribute__(\"domain\").__getattribute__(\"values\"),\n",
    "    HP_ACTIVATION2.__getattribute__(\"domain\").__getattribute__(\"values\"),\n",
    "    HP_ACTIVATION3.__getattribute__(\"domain\").__getattribute__(\"values\"),\n",
    "    HP_INIT.__getattribute__(\"domain\").__getattribute__(\"values\"),\n",
    "    HP_MOMENTUM.__getattribute__(\"domain\").__getattribute__(\"values\"),\n",
    "    HP_LEARNING_RATE.__getattribute__(\"domain\").__getattribute__(\"values\"),\n",
    "    HP_DROPOUT1.__getattribute__(\"domain\").__getattribute__(\"values\"),\n",
    "    HP_DROPOUT2.__getattribute__(\"domain\").__getattribute__(\"values\"),\n",
    "    HP_EPOCH.__getattribute__(\"domain\").__getattribute__(\"values\")\n",
    "]\n",
    "\n",
    "\n",
    "allcombination = list(itertools.product(*gridParameters))\n",
    "print(len(allcombination))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading training and testing data from the csv file\n",
    "trainDf = pd.read_csv ('data/csv/monks-3Train.csv',header=None).to_numpy()\n",
    "testDf = pd.read_csv ('data/csv/monks-3Test.csv',header=None).to_numpy()\n",
    "trainDf = minmax_scale(trainDf, feature_range=(0,1), axis=0)\n",
    "testDf = minmax_scale(trainDf, feature_range=(0,1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing trainDf for training\n",
    "trainX = trainDf[:, 1:7]\n",
    "trainY = trainDf[:, 0]\n",
    "#Preparing testDf for validation\n",
    "testX = testDf[:, 1:7]\n",
    "testY = testDf[:, 0]\n",
    "#trainX = scaler.fit_transform(trainX)\n",
    "#trainY = scaler.fit_transform(trainY)\n",
    "testX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as ks\n",
    "tensorboard_callback = ks.callbacks.TensorBoard(log_dir=\"./log\",histogram_freq=1,write_graph=True,update_freq=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(lr=0.1,momentum=0.9,dropout1=0.4,dropout2=0.4,g_hiddeLayerunit1=4,g_hiddeLayerunit2=4,activation1=\"tanh\",activation2=\"tanh\",activation3=\"sigmoid\",init_mode='uniform', g_decay=0.01):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(g_hiddeLayerunit1, input_dim=6, kernel_initializer=init_mode, activation=activation1))\n",
    "    model.add(Dropout(dropout1)),\n",
    "    model.add(Dense(g_hiddeLayerunit2, kernel_initializer=init_mode, activation=activation2,kernel_regularizer=regularizers.l1(0.01))) # l1 regularization parameter could also be something we can also grid search for.\n",
    "    model.add(Dropout(dropout2)),\n",
    "    model.add(Dense(1, activation3))\n",
    "    sgd = SGD(lr=lr, momentum=momentum, decay=g_decay, nesterov=False,)  # We can add decay to hyper parameter list to get optimum value. \n",
    "    model.summary()\n",
    "    model.compile(optimizer=sgd, loss='mean_squared_error',metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams,tensorboard_callback):\n",
    "    \n",
    "    \n",
    "  model = create_model(lr=hparams[HP_LEARNING_RATE],momentum=hparams[HP_MOMENTUM],dropout1=hparams[HP_DROPOUT1],dropout2=hparams[HP_DROPOUT2],g_hiddeLayerunit1=hparams[HP_NUM_UNITS1],g_hiddeLayerunit2=hparams[HP_NUM_UNITS1],activation1=hparams[HP_ACTIVATION1],activation2=hparams[HP_ACTIVATION2],activation3=hparams[HP_ACTIVATION3],init_mode=hparams[HP_INIT], g_decay=0.01)\n",
    "\n",
    "\n",
    "  model.fit(trainX, trainY, epochs=hparams[HP_EPOCH], callbacks=[tensorboard_callback],verbose=0) # Run with 1 epoch to speed things up for demo purposes\n",
    "  _, accuracy = model.evaluate(testX, testY)\n",
    "  return accuracy\n",
    "\n",
    "def run(run_dir,hparams,tensorboard_callback):\n",
    "  with tf.summary.create_file_writer(run_dir).as_default():\n",
    "    hp.hparams(hparams)  # record the values used in this trial\n",
    "    accuracy = train_test_model(hparams,tensorboard_callback)\n",
    "    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)\n",
    "\n",
    "session_num = 0\n",
    "class myThread (threading.Thread):\n",
    "   def __init__(self, threadID,run_dir,hparams,tensorboard_callback):\n",
    "      threading.Thread.__init__(self)\n",
    "      self.threadID = threadID\n",
    "      self.run_dir = run_dir\n",
    "      self.hparams = hparams\n",
    "      self.tensorboard_callback=tensorboard_callback\n",
    "   def run(self):\n",
    "      print(\"Starting \" + self.name)\n",
    "      run(self.run_dir,self.hparams,self.tensorboard_callback)\n",
    "      print(\"Exiting \" + self.name)\n",
    "\n",
    "\n",
    "# for batch_size in HP_BATCH_SIZE.domain.values:\n",
    "#     for num_units1 in HP_NUM_UNITS1.domain.values:\n",
    "#       for num_units2 in HP_NUM_UNITS2.domain.values:\n",
    "#         for activation1 in HP_ACTIVATION1.domain.values:\n",
    "#           for activation2 in HP_ACTIVATION2.domain.values:\n",
    "#             for activation3 in HP_ACTIVATION3.domain.values:\n",
    "#               for init_mode in HP_INIT.domain.values:\n",
    "#                 for momentum in HP_MOMENTUM.domain.values:\n",
    "#                   for lr in HP_LEARNING_RATE.domain.values:\n",
    "#                       for dropout_rate1 in HP_DROPOUT1.domain.values:\n",
    "#                         for dropout_rate2 in HP_DROPOUT2.domain.values:\n",
    "#                         #for optimizer in HP_OPTIMIZER.domain.values:\n",
    "#                             for epoch in HP_EPOCH.domain.values:\n",
    "#                               hparams = {\n",
    "#                                   HP_NUM_UNITS1: num_units1,\n",
    "#                                   HP_NUM_UNITS2: num_units2,\n",
    "#                                   HP_ACTIVATION1:activation1,\n",
    "#                                   HP_ACTIVATION2:activation2,\n",
    "#                                   HP_ACTIVATION3:activation3,\n",
    "#                                   HP_INIT:init_mode,\n",
    "#                                   HP_MOMENTUM:momentum,\n",
    "#                                   HP_LEARNING_RATE:lr,\n",
    "#                                   HP_DROPOUT1: dropout_rate1,\n",
    "#                                   HP_DROPOUT2: dropout_rate2,\n",
    "#                                   #HP_OPTIMIZER: optimizer,\n",
    "#                                   HP_EPOCH:epoch,\n",
    "#                                   HP_BATCH_SIZE:batch_size,\n",
    "#                               }\n",
    "#                               run_name = \"run-%d\" % session_num\n",
    "#                               tensorboard_callback = ks.callbacks.TensorBoard(log_dir=\"logs/scalar/\"+run_name,histogram_freq=1,write_graph=True,update_freq=1)\n",
    "#                               print('--- Starting trial: %s' % run_name)\n",
    "#                               print({h.name: hparams[h] for h in hparams})\n",
    "#                               thread=myThread(session_num,'logs/hparam_tuning/' + run_name, hparams,tensorboard_callback)\n",
    "#                               thread.start()\n",
    "#                               session_num += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for batch_size in HP_BATCH_SIZE.domain.values:\n",
    "    for num_units1 in HP_NUM_UNITS1.domain.values:\n",
    "      for num_units2 in HP_NUM_UNITS2.domain.values:\n",
    "        for activation1 in HP_ACTIVATION1.domain.values:\n",
    "          for activation2 in HP_ACTIVATION2.domain.values:\n",
    "            for activation3 in HP_ACTIVATION3.domain.values:\n",
    "              for init_mode in HP_INIT.domain.values:\n",
    "                for momentum in HP_MOMENTUM.domain.values:\n",
    "                  for lr in HP_LEARNING_RATE.domain.values:\n",
    "                      for dropout_rate1 in HP_DROPOUT1.domain.values:\n",
    "                        for dropout_rate2 in HP_DROPOUT2.domain.values:\n",
    "                        #for optimizer in HP_OPTIMIZER.domain.values:\n",
    "                            for epoch in HP_EPOCH.domain.values:\n",
    "                              hparams = {\n",
    "                                  HP_NUM_UNITS1: num_units1,\n",
    "                                  HP_NUM_UNITS2: num_units2,\n",
    "                                  HP_ACTIVATION1:activation1,\n",
    "                                  HP_ACTIVATION2:activation2,\n",
    "                                  HP_ACTIVATION3:activation3,\n",
    "                                  HP_INIT:init_mode,\n",
    "                                  HP_MOMENTUM:momentum,\n",
    "                                  HP_LEARNING_RATE:lr,\n",
    "                                  HP_DROPOUT1: dropout_rate1,\n",
    "                                  HP_DROPOUT2: dropout_rate2,\n",
    "                                  #HP_OPTIMIZER: optimizer,\n",
    "                                  HP_EPOCH:epoch,\n",
    "                                  HP_BATCH_SIZE:batch_size,\n",
    "                              }\n",
    "                              run_name = \"run-%d\" % session_num\n",
    "                              tensorboard_callback = ks.callbacks.TensorBoard(log_dir=\"logs/scalar/\"+run_name,histogram_freq=1,write_graph=True,update_freq=1)\n",
    "                              print('--- Starting trial: %s' % run_name)\n",
    "                              print({h.name: hparams[h] for h in hparams})\n",
    "                              run('logs/hparam_tuning/' + run_name, hparams,tensorboard_callback)\n",
    "                              session_num += 1\n",
    "\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time \n",
    "def create_model(lr=0.1,momentum=0.9,g_hiddeLayerunit1=4,g_hiddeLayerunit2=4,activation1=\"tanh\",activation2=\"tanh\",activation3=\"sigmoid\",init_mode='uniform', g_decay=0.01):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(g_hiddeLayerunit1, input_dim=6, kernel_initializer=init_mode, activation=activation1))\n",
    "    model.add(Dropout(0.4)),\n",
    "    model.add(Dense(g_hiddeLayerunit2, kernel_initializer=init_mode, activation=activation2,kernel_regularizer=regularizers.l1(0.01))) # l1 regularization parameter could also be something we can also grid search for.\n",
    "    model.add(Dropout(0.4)),\n",
    "    model.add(Dense(1, activation3))\n",
    "    sgd = SGD(lr=lr, momentum=momentum, decay=g_decay, nesterov=False,)  # We can add decay to hyper parameter list to get optimum value. \n",
    "    model.compile(optimizer=sgd, loss='mean_squared_error',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "class KerasRegressorTB(KerasClassifier):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(KerasClassifier, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def fit(self, x, y, log_dir=None, **kwargs):\n",
    "        cbs = None\n",
    "        if log_dir is not None:\n",
    "            # Make sure the base log directory exists\n",
    "            try:\n",
    "                os.makedirs(log_dir)\n",
    "            except OSError:\n",
    "                pass\n",
    "            params = self.get_params()\n",
    "            conf = \",\".join(\"{}={}\".format(k, params[k])\n",
    "                            for k in sorted(params))\n",
    "            conf_dir_base = os.path.join(log_dir, conf)\n",
    "            # Find a new directory to place the logs\n",
    "            for i in itertools.count():\n",
    "                try:\n",
    "                    conf_dir = \"{}_split-{}\".format(conf_dir_base, i)\n",
    "                    os.makedirs(conf_dir)\n",
    "                    break\n",
    "                except OSError:\n",
    "                    pass\n",
    "            cbs = [ks.callbacks.TensorBoard(log_dir=conf_dir, histogram_freq=0,\n",
    "                               write_graph=True, write_images=False)]\n",
    "        super(KerasRegressorTB, self).fit(x, y, callbacks=cbs, **kwargs)\n",
    "\n",
    "        \n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "g_hiddeLayerunit1=[4,8,16]\n",
    "g_hiddeLayerunit2=[4,8,16]\n",
    "g_decay = [0.01] # more estimations can be added\n",
    "activation1 = [\"relu\", \"tanh\",\"sigmoid\",\"softmax\"]\n",
    "activation2 = [\"relu\", \"tanh\",\"sigmoid\",\"softmax\"]\n",
    "activation3 = [\"relu\", \"tanh\",\"sigmoid\",\"softmax\"]\n",
    "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "lr=np.arange(0.1, 0.9, 0.1).tolist()\n",
    "momentum=np.arange(0.1, 0.9, 0.1).tolist()\n",
    "param_grid = dict(\n",
    "    lr=lr,\n",
    "   # g_hiddeLayerunit1=g_hiddeLayerunit1,\n",
    "   # g_hiddeLayerunit2=g_hiddeLayerunit2,\n",
    "   # activation1=activation1,\n",
    "   # activation2=activation2,\n",
    "   # activation3=activation3,\n",
    "   # batch_size=batch_size,\n",
    "   # init_mode=init_mode,\n",
    "   # g_decay = g_decay,\n",
    "   # epochs=epochs\n",
    "    )\n",
    "model = KerasRegressorTB(build_fn=create_model)\n",
    "print(\"HE\")\n",
    "\n",
    "\n",
    "print(\"HEHE\")\n",
    "start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid,fit_params={'log_dir': './Graph'},n_jobs=1,cv=3,verbose=verbose_level)\n",
    "\n",
    "\n",
    "print(\"HEHEHE\")\n",
    "grid_result = grid.fit(trainX, trainY)\n",
    "timer(start_time) # timing ends here for \"start_time\" variable\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "print(\"Mean\\tSTD\\tParams\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
